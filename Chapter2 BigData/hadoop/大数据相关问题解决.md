[TOC]

# 大数据相关问题解决

## Hive

### 1.查询hivemeta信息，查到的numRows为-1

| 集群厂商 | 集群版本 | 是否高可用 | 是否开启认证 |
| -------- | -------- | ---------- | ------------ |
| cdh      | 不限     | 不限       | 不限         |

在hivemeta库中可以通过以下sql查询表的元数据信息

`SELECT  *  FROM  TABLE_PARAMS  WHERE  tbl_id = 45857`

其中numRows会被用来统计为表的行数，但是发现有些表查出来行数为-1

#### 可能原因

> 对于一个新创建的表，默认情况下，如果通过INSERT OVERWRITE的方式插入数据，那么Hive会自动将该表或分区的统计信息更新到元数据。
>
> 有一个参数来控制是否自动统计，hive.stats.autogather，默认为true.

可能是因为这个表新建后没有通过这种方式插入过数据，所以表没有进行过统计，默认信息即为numRows=-1

#### 解决方案

使用命令 **ANALYZE TABLE tableName COMPUTE STATISTICS;** 统计元数据信息

再查询时，numRows变为0



### 2. bucketId out of range: -1 (state=,code=0)

| 集群厂商 | 集群版本 | 是否高可用 | 是否开启认证 |
| -------- | -------- | ---------- | ------------ |
| hdp      | 3.1.1    | 是         | 是           |

执行一个普普通通的 SELECT * FROM student WHERE 1 = 1 LIMIT 5;报错

Error: java.io.IOException: java.lang.IllegalArgumentException: bucketId out of range: -1 (state=,code=0)

#### 可能原因

#### 解决方案



### 3.集群客户端使用hive命令连接，报错认证失败

| 集群厂商 | 集群版本 | 是否高可用 | 是否开启认证 |
| -------- | -------- | ---------- | ------------ |
| hdp      | 3.1.1    | 是         | 是           |

报错信息忘了拷贝了

#### 可能原因

客户端java 的安全认证文件没有下发，kerberos加密解密有问题

需要jar包：

- local_policy.jar 
- US_export_policy.jar

#### 解决方案

拷贝安全认证文件到客户端

scp root@ip:/opt/third/jdk/jre/lib/security/*.jar  /opt/third/jdk/jre/lib/security/



### 4.运行hive任务卡在Tez session hasn't been created yet. Opening session

| 集群厂商 | 集群版本 | 是否高可用 | 是否开启认证 |
| -------- | -------- | ---------- | ------------ |
| hdp      | 3.1.1    | 是         | 是           |

![tezSession](https://markdown-image-upload.oss-cn-beijing.aliyuncs.com/img/tezSession.png)

#### 可能原因

没有指定tez队列，无法获取到足够的资源启动任务

#### 解决方案

设置tez队列 set tez.queue.name = 

#### 问题拓展

 hive 设置队列需要根据所使用的引擎进行对应的设置才会有效果，否则无效

```xml
# 设置引擎

set hive.execution.engine=mr;  
set hive.execution.engine=spark;  
set hive.execution.engine=tez;  

# 如果使用的是mr(原生mapreduce)
SET mapreduce.job.queuename=etl;
# 如果使用的引擎是tez
set tez.queue.name=etl
# 设置队列（etl为队列名称，默认为default）
```

> MapReduce:是一种离线计算框架，用于大规模数据集（大于1TB）的并行运算，将一个算法抽象成Map和Reduce两个阶段进行处理，非常适合数据密集型计算。
>
> Spark:Spark是UC Berkeley AMP lab所开源的类Hadoop MapReduce的通用的并行计算框架，Spark基于map reduce算法实现的分布式计算，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map reduce的算法。
>
> Storm:MapReduce也不适合进行流式计算、实时分析，比如广告点击计算等。Storm是一个免费开源、分布式、高容错的实时计算系统。Storm令持续不断的流计算变得容易，弥补了Hadoop批处理所不能满足的实时要求。Storm经常用于在实时分析、在线机器学习、持续计算、分布式远程调用和ETL等领域
>
> Tez: 是基于Hadoop Yarn之上的DAG（有向无环图，Directed Acyclic Graph）计算框架。它把Ｍap/Reduce过程拆分成若干个子过程，即Map被拆分成Input、Processor、Sort、Merge和Output， Reduce被拆分成Input、Shuffle、Sort、Merge、Processor和Output等。同时可以把多个Ｍap/Reduce任务组合成一个较大的DAG任务，减少了Ｍap/Reduce之间的文件存储。同时合理组合其子过程，也可以减少任务的运行时间

![img](/Users/jacobzheng/Documents/work/插件池/tez和MR对比.png)

### 5.Unable to read HiveServer2 configs from ZooKeeper

| 集群厂商 | 集群版本 | 是否高可用 | 是否开启认证 |
| -------- | -------- | ---------- | ------------ |
| fi       | 5.15.2   | 是         | 是           |

没有进行zk认证



## HDFS

### 1.No common protection layer between client and server

| 集群厂商 | 集群版本 | 是否高可用 | 是否开启认证 |
| -------- | -------- | ---------- | ------------ |
| cdh      | 5.15.2   | 是         | 是           |

```java
javax.security.sasl.SaslException: No common protection layer between client and server
	at com.sun.security.sasl.gsskerb.GssKrb5Client.doFinalHandshake(GssKrb5Client.java:251)
	at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:186)
	at org.apache.hadoop.security.SaslRpcClient.saslEvaluateToken(SaslRpcClient.java:483)
	at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:427)
	at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:594)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:396)
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:761)
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:757)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1920)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:756)
	at org.apache.hadoop.ipc.Client$Connection.access$3000(Client.java:396)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1557)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1441)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
```

#### 可能原因

该异常由服务端与客户端配置项hadoop.rpc.protection不一致导致。

#### 解决方案

修正服务端hadoop.rpc.protection配置，确保两端一致,重启服务。

#### 问题拓展

可选值（需要和集群配置保持同步）：authentication，integrity，privacy

在hadoop服务和客户端之间传输的数据可以在线上加密。在**core-site.xml**中将`hadoop.rpc.protection`设置为**privacy**会激活数据加密。以上三项分别为 

- authentication【认证：仅认证（默认)】
- integrity 【完整性：除了认证之外的完整性检查】
- Privacy 【隐私：除了完整性检查之外的数据加密】



### 2.Can't get Master Kerberos principal for use as renewer

| 集群厂商 | 集群版本 | 是否高可用 | 是否开启认证 |
| -------- | -------- | ---------- | ------------ |
| cdh      | 5.15.2   | 是         | 是           |

![image-20190909095631072](https://markdown-image-upload.oss-cn-beijing.aliyuncs.com/img/image-20190909095631072.png)

#### 可能原因

获取fileReader的时候没有传入yarn.resourcemanager.principal参数。

#### 解决方案

传入yarn.resourcemanager.principal参数。



### 3.Does not contain a valid host:port authority: hdp-2.6-node1.dtwave.com

#### 可能原因

#### 解决方案





## HBase

### 1.KeeperErrorCode = NoNode for /hbase/meta-region-server

| 集群厂商 | 集群版本 | 是否高可用 | 是否开启认证 |
| -------- | -------- | ---------- | ------------ |
| hdp      | 3.1.1    | 是         | 是           |

#### 可能原因

hbase.znode.parent 没有配置正确，客户端需要与集群使用的一致。

#### 解决方案

修正配置

## Ranger

### 1.User doesn't have necessary permission to grant access

调用rangerApi授权出现以上返回，但是我的用户是admin用户，照理说是有所有权限的。

#### 问题原因

![ranger](https://markdown-image-upload.oss-cn-beijing.aliyuncs.com/img/ranger.png)

可能是因为没有把用户添加到具体的规则中

Delegate Admin

2.

## kerberos

### 1.Fail to create credential. (63) - No service creds

| 集群厂商 | 集群版本 | 是否高可用 | 是否开启认证 |
| -------- | -------- | ---------- | ------------ |
| hdp      | 2.6      | 是         | 是           |

#### 可能原因

该异常由服务端与客户端配置项hadoop.rpc.protection不一致导致。

#### 解决方案